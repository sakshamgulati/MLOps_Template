{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.ui.workspace.cloud import CloudWorkspace\n",
    "\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataQualityPreset\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently.metrics import *\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.tests import *\n",
    "from evidently.test_preset import DataDriftTestPreset\n",
    "from evidently.tests.base_test import TestResult, TestStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sakshamgulati/.local/share/virtualenvs/MLOps_Template-k_6XISXV/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "adult_data = datasets.fetch_openml(name=\"adult\", version=2, as_frame=\"auto\")\n",
    "adult = adult_data.frame\n",
    "adult_ref = adult[~adult.education.isin([\"Some-college\", \"HS-grad\", \"Bachelors\"])]\n",
    "adult_prod = adult[adult.education.isin([\"Some-college\", \"HS-grad\", \"Bachelors\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(id=UUID('687924e5-85e8-4381-ad0b-f972ffd195bc'), name='Test Project', description='My project description', dashboard=DashboardConfig(name='Test Project', panels=[], tabs=[], tab_id_to_panel_ids={}), team_id=UUID('74fdd884-9679-4693-819b-a6695e652e25'), date_from=None, date_to=None, created_at=datetime.datetime(2024, 6, 10, 21, 45, 9, 133912))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "#connecting to evidently cloud workspace using API token\n",
    "ws = CloudWorkspace(\n",
    "token=os.getenv(\"evi_api\"),\n",
    "url=\"https://app.evidently.cloud\")\n",
    "\n",
    "# #creating a project in the workspace\n",
    "__project_name__=\"Test Project\"\n",
    "__team_id__=\"74fdd884-9679-4693-819b-a6695e652e25\"\n",
    "\n",
    "project = ws.create_project(__project_name__,team_id=__team_id__)\n",
    "project.description = \"My project description\"\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving stock price data from Alpha Vantage (This may take a while)...\n",
      "Data has been successfully downloaded...\n",
      "Sorting the retrieved data into a dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1284/1284 [00:01<00:00, 773.02it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def request_stock_price_hist(symbol, token, sample = False):\n",
    "    if sample == False:\n",
    "        q_string = 'https://www.alphavantage.co/query?function=TIME_SERIES_WEEKLY_ADJUSTED&symbol={}&outputsize=full&apikey={}'\n",
    "    else:\n",
    "        q_string = 'https://www.alphavantage.co/query?function=TIME_SERIES_WEEKLY_ADJUSTED&symbol={}&apikey={}'\n",
    "\n",
    "    print(\"Retrieving stock price data from Alpha Vantage (This may take a while)...\")\n",
    "    r = requests.get(q_string.format(symbol, token))\n",
    "    print(\"Data has been successfully downloaded...\")\n",
    "    date = []\n",
    "    colnames = list(range(0, 6))\n",
    "    df = pd.DataFrame(columns = colnames)\n",
    "    print(\"Sorting the retrieved data into a dataframe...\")\n",
    "    for i in tqdm(r.json()['Weekly Adjusted Time Series'].keys()):\n",
    "        date.append(i)\n",
    "        row = pd.DataFrame.from_dict(r.json()['Weekly Adjusted Time Series'][i], orient='index').reset_index().T[1:]\n",
    "        df = pd.concat([df, row], ignore_index=True)\n",
    "    df.columns = [\"open\", \"high\", \"low\", \"close\", \"adjusted close\", \"volume\", \"dividend amount\"]\n",
    "    df['date'] = date\n",
    "    df = df.set_index('date')\n",
    "    df = df.sort_index(ascending=True)\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "ALPHA_VANTAGE_API_KEY=os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
    "data=request_stock_price_hist('IBM', ALPHA_VANTAGE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch data from the API\n",
    "data_report = Report(\n",
    "       metrics=[\n",
    "           DataQualityPreset(),\n",
    "       ],\n",
    "    )\n",
    "data_report.run(reference_data=None, current_data=data)\n",
    "ws.add_report(project.id, data_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_report = Report(\n",
    "        metrics=[\n",
    "            DataDriftPreset(stattest='psi', stattest_threshold='0.3'),\n",
    "            DataQualityPreset(),\n",
    "        ],\n",
    "        timestamp=datetime.datetime.now(),\n",
    "    )\n",
    "\n",
    "data_report.run(reference_data=adult_ref, current_data=adult_prod.iloc[0 : 100, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need three things\n",
    "1. Data/Feature Drift-  data schema changes,A stale data source,Unexpected inputs. \n",
    "2. Model Prediction Drift-Track the descriptive statistics of the model output (e.g., mean predicted values, standard deviation).\n",
    "Apply statistical tests (e.g., Kolmogorov-Smirnov test, Chi-squared test) to compare the most recent model outputs with the older ones.\n",
    "Use probability distance metrics to compare distributions (e.g., Wasserstein distance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps_Template-k_6XISXV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
